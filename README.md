<h2 align="left"> Arun Kumar RN </h2>

<div align="left" style="height:128px;width:128px">
<img src="src/me.png" style="width:100%; height:100%">
</div>

Data Scientist at Enquero<br/>
Email: arun [dot] rvbe [at] gmail [dot] com <br/>
CV: As of December 2020


## About Me
I am a Data Scientist at Enquero. My work focuses on designing and building ML algorithms that complement the software products. In my free time, I ideate on integrating ML algorithms and hardware products. I study Machine Learning, product design, and the intersection between the two.  

## Problems that I have solved
#### 1. Anomaly Detection at scale
#### 2. Vision that can detect objects, depth, and planar regions
#### 3. Similarity Algorithm at Scale
#### 4. Model Explainability at Scale
#### 5. Deploying ML algorithms along with Software products in a big data environment
#### 6. Testing and Monitoring Deployed ML model in a Software product
#### 7. Designing Hardware + ML systems

## Learnings
### Understanding fundamentals of PyTorch
- CUDA
	 1. To understand CUDA, we need to understand what GPU is.  GPU (Graphics Processing Unit) is a hardware used for specialized computing tasks. As the name suggests, this was initialized developed to process graphics faster than CPU. GPU processes faster due to its parallel computing property that is, GPU can break down an long independent task into smaller tasks and run all those tasks in parallel. 
	 2. Due to this parallel computing nature, GPU found its application in Deep learning, which is embarrassingly parallel. 
	 [placeholder for parallel processing image]
	 3. Nvidia is the industry leader in developing GPUs. With GPU as a hardware, a software layer was needed to optimize the computation for different domain specific tasks. This software layer is CUDA, which was developed by Nvidia. Simply put, CUDA is an API to GPU. There's cuDNN library which can used to work with CUDA to develop further
	 [Architecture flow [hardware (GPU) software(CUDA) library(cuDNN) framework(PyTorch)]]
